{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7f42030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "from utils.H264 import *\n",
    "from utils.ycbcr_conv import *\n",
    "from utils.check import *\n",
    "from pathlib import Path\n",
    "\n",
    "# create directrot output if not exist\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "def read_image_into_rgb(path):\n",
    "    img = Image.open(path)\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    img = img.convert(\"RGB\")\n",
    "    rgb = np.array(img)\n",
    "    print(rgb.shape, rgb.dtype)              # (H, W, 3) uint8\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff602613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "# ipynb_root = Path(__file__).parent\n",
    "input_img_path = Path(\"img\") / \"trump.jpg\"\n",
    "output_img_path = Path(\"output\") / \"recover_trump.jpg\"\n",
    "rgb_image = read_image_into_rgb(input_img_path)\n",
    "ycbcr_image = rgb_2_ycbcr(rgb_image=rgb_image)\n",
    "recover_rgb_image = ycbcr_2_rgb(ycbcr_image=ycbcr_image)\n",
    "Image.fromarray(recover_rgb_image, mode=\"RGB\").save(output_img_path, quality=90, optimize=True, progressive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7688a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3) uint8\n",
      "(512, 512, 3) uint8\n",
      "convertion diff: 0.5409317016601562\n"
     ]
    }
   ],
   "source": [
    "original_image = read_image_into_rgb(input_img_path)\n",
    "recover_image = read_image_into_rgb(output_img_path)\n",
    "diff_two_tensor(A=original_image, B=recover_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fda8f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512) uint8\n"
     ]
    }
   ],
   "source": [
    "Y_tensor = ycbcr_image[...,0]\n",
    "print(Y_tensor.shape, Y_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fa77ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 32, 32) (512, 512)\n",
      "convertion diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "frames, _ = macro_block_partition(Y_tensor=Y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86226d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 16, 16) (32, 32)\n",
      "convertion diff: 0.0\n",
      "at blk (0, 0) we have op: 0\n",
      "omg:  (16, 16) (16, 16) (16, 16)\n",
      "haha:  (16, 16)\n",
      "123456:  (16, 16)\n",
      "float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'right_shift' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m op_mode \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m QP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m13\u001b[39m\n\u001b[0;32m----> 4\u001b[0m blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_a_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQP\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/popo_train_cpu/iclab_relate/lab5/utils/H264.py:50\u001b[0m, in \u001b[0;36mconsume_a_frame\u001b[0;34m(frame, op_mode, QP)\u001b[0m\n\u001b[1;32m     48\u001b[0m X \u001b[38;5;241m=\u001b[39m residual_computation(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mcut_out_ans, predicted\u001b[38;5;241m=\u001b[39mpredicted)\n\u001b[1;32m     49\u001b[0m W \u001b[38;5;241m=\u001b[39m integer_transform(X\u001b[38;5;241m=\u001b[39mX)\n\u001b[0;32m---> 50\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mquantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m W_bar \u001b[38;5;241m=\u001b[39m de_quantization(Z\u001b[38;5;241m=\u001b[39mZ, QP\u001b[38;5;241m=\u001b[39mQP)\n\u001b[1;32m     52\u001b[0m X_bar \u001b[38;5;241m=\u001b[39m reverse_integer_transform(W_bar\u001b[38;5;241m=\u001b[39mW_bar)\n",
      "File \u001b[0;32m~/Desktop/popo_train_cpu/iclab_relate/lab5/utils/H264.py:101\u001b[0m, in \u001b[0;36mquantization\u001b[0;34m(W, QP)\u001b[0m\n\u001b[1;32m     99\u001b[0m         W_sign \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(W_sub)\n\u001b[1;32m    100\u001b[0m         abs_W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(W_sub)\n\u001b[0;32m--> 101\u001b[0m         abs_Z \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mabs_W\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq_bits\u001b[49m\n\u001b[1;32m    102\u001b[0m         grids[i, j] \u001b[38;5;241m=\u001b[39m abs_Z \u001b[38;5;241m*\u001b[39m W_sign\n\u001b[1;32m    103\u001b[0m Z \u001b[38;5;241m=\u001b[39m grids\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(h, w)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'right_shift' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "traget_frame = frames[1, 1]\n",
    "op_mode = [0, 0, 0, 1]\n",
    "QP = 13\n",
    "blocks, _ = consume_a_frame(frame=traget_frame, op_mode=op_mode, QP=QP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "popo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
